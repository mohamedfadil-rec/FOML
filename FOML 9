# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# Step 1: Create or load a dataset
X = np.random.rand(100, 2)  # 100 points in 2D space

# Step 2: Compute WCSS (Within-Cluster Sum of Squares) for different k values
wcss = []
K_values = range(1, 11)  # test k from 1 to 10

for k in K_values:
    kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)
    kmeans.fit(X)
    wcss.append(kmeans.inertia_)  # inertia_ = WCSS

# Step 3: Plot the Elbow Curve
plt.figure(figsize=(8,5))
plt.plot(K_values, wcss, 'bo-', linewidth=2)
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('WCSS (Inertia)')
plt.grid(True)
plt.show()


# Import required libraries
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# Step 1: Create sample data (2D points)
np.random.seed(42)
X = np.random.rand(100, 2)  # 100 points with 2 features

# Step 2: Choose number of clusters (k)
k = 3

# Step 3: Create and train the K-Means model
kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)
kmeans.fit(X)

# Step 4: Get cluster predictions and centroids
labels = kmeans.predict(X)
centroids = kmeans.cluster_centers_

# Step 5: Visualize clusters
plt.figure(figsize=(8,6))
plt.scatter(X[:,0], X[:,1], c=labels, cmap='rainbow', s=50)
plt.scatter(centroids[:,0], centroids[:,1], c='black', marker='X', s=200, label='Centroids')
plt.title('K-Means Clustering (k=3)')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.show()

